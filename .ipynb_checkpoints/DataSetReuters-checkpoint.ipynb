{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727033ee-d822-4006-96e8-d4697d13595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584dea9-2db9-4e4b-a6d0-7753be07c33d",
   "metadata": {},
   "source": [
    "Loading the Dataset:\n",
    "\n",
    "The Reuters dataset is loaded, with a vocabulary size limited to the top 10,000 most frequently occurring words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd1bed-893e-4a1a-a047-e284e17cf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Reuters dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = datasets.reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995956f1-bd67-4e81-87c4-0f0fe6b3d0b8",
   "metadata": {},
   "source": [
    "Decoding Function:\n",
    "\n",
    "A function is provided to decode the newswires back to text for better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101db986-61fd-46d6-8bf6-2c6914d6f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode newswires back to text\n",
    "word_index = datasets.reuters.get_word_index()\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794e04a-a078-4e2f-adc2-43f320a53777",
   "metadata": {},
   "source": [
    "Preprocessing the Data:\n",
    "\n",
    "The newswire data is vectorized into binary matrices, where each entry corresponds to a word in the vocabulary.\n",
    "The labels are one-hot encoded for categorical classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab629342-785b-43f6-b791-6bcb19e4c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_newswire(text):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])\n",
    "\n",
    "# Preprocess the data\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.0\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da48093-aa7f-4bdf-b51b-e0499feb5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(train_labels)\n",
    "y_test = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad94db4-b98a-4f84-b1f6-d8c41553db9d",
   "metadata": {},
   "source": [
    "Building the Model:\n",
    "\n",
    "A simple neural network with two hidden layers, each with 64 units and ReLU activation, and an output layer with 46 units (one for each class) and softmax activation is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2d4ae-9668-45ff-b52d-54858009fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8cba3-6b7e-4d6e-b53d-4dc21996b3ca",
   "metadata": {},
   "source": [
    "Compiling the Model:\n",
    "\n",
    "The model is compiled using the Adam optimizer and categorical crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c27c1-7404-4bdf-b3b4-4079cd39c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf90aa2-8583-45eb-9a96-4beb16aa9d9c",
   "metadata": {},
   "source": [
    "Training the Model:\n",
    "\n",
    "The model is trained for 10 epochs with a batch size of 512, and the validation data is used to monitor performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14f2c5-9fdf-49c1-a2ea-b9f8d224205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190e9e9-a94e-4b52-9dd0-e69326facab0",
   "metadata": {},
   "source": [
    "Evaluating the Model:\n",
    "\n",
    "The model's performance is evaluated on the test data, and the test accuracy is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f64f39-5205-4103-81c3-f0362711512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351dd1da-3889-4165-8663-bc696d39688a",
   "metadata": {},
   "source": [
    "Plotting Results:\n",
    "\n",
    "The training and validation accuracy and loss are plotted to visualize the model's performance over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94306d4d-05fa-4223-a6e1-50ff77c4538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
